main_config:
  batch_size: 1000
  # model_name: "Alibaba-NLP/gte-large-en-v1.5"
  model_name: "intfloat/e5-mistral-7b-instruct"
  context_length: 5000

Alibaba-NLP/gte-large-en-v1.5:
  context_length: 8192
  chunk_size: 1000
  chunk_overlap: 200

all-MiniLM-L6-v2:
  context_length: 256
  chunk_size: 1000
  chunk_overlap: 200

intfloat/e5-mistral-7b-instruct:
  context_length: 32768
  embedding_size: 4096
  chunk_size: 25000
  chunk_overlap: 400
